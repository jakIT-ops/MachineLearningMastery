{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32730f99-bcb0-4f06-a476-71227e1a86be",
   "metadata": {},
   "source": [
    "Lesson 01: Introduction to Theano.\n",
    "\n",
    "Theano is a Python library for fast numerical computation to aid in the development of deep learning models.\n",
    "\n",
    "At it’s heart Theano is a compiler for mathematical expressions in Python. It knows how to take your structures and turn them into very efficient code that uses NumPy and efficient native libraries to run as fast as possible on CPUs or GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc44a35e-45ca-4912-bba5-94255d915e23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Theano\n",
      "  Downloading Theano-1.0.5.tar.gz (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.9.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting numpy>=1.9.1\n",
      "  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: Theano\n",
      "  Building wheel for Theano (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Theano: filename=Theano-1.0.5-py3-none-any.whl size=2668109 sha256=af726fa557ce6303712e288a3e2d008bf928506c192d69cc28a530543b892545\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/e6/7d/2267d21a99e4ab8276f976f293b4ff23f50c9d809f4a216ebb\n",
      "Successfully built Theano\n",
      "Installing collected packages: six, numpy, scipy, Theano\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1 requires pillow!=8.3.*,>=5.3.0, which is not installed.\n",
      "torchvision 0.13.1 requires requests, which is not installed.\n",
      "torchvision 0.13.1 requires typing-extensions, which is not installed.\n",
      "matplotlib 3.7.0 requires contourpy>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.0 requires cycler>=0.10, which is not installed.\n",
      "matplotlib 3.7.0 requires fonttools>=4.22.0, which is not installed.\n",
      "matplotlib 3.7.0 requires kiwisolver>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.0 requires packaging>=20.0, which is not installed.\n",
      "matplotlib 3.7.0 requires pillow>=6.2.0, which is not installed.\n",
      "matplotlib 3.7.0 requires pyparsing>=2.3.1, which is not installed.\n",
      "matplotlib 3.7.0 requires python-dateutil>=2.7, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Theano-1.0.5 numpy-1.24.2 scipy-1.10.1 six-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d843a9-985d-4c44-a72e-9617685325a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You can find the C code in this temporary file: /tmp/theano_compilation_error_p4eih7k3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'theano' has no attribute 'gof' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/lazylinker_c.py:76\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m!=\u001b[39m actual_version:\n\u001b[0;32m---> 76\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion check of the existing lazylinker compiled file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Looking for version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but found \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra debug information: force_compile=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, _need_reload=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m     80\u001b[0m                     version,\n\u001b[1;32m     81\u001b[0m                     actual_version, force_compile, _need_reload))\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/lazylinker_c.py:99\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m!=\u001b[39m actual_version:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion check of the existing lazylinker compiled file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Looking for version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but found \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra debug information: force_compile=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m _need_reload=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    104\u001b[0m                 version,\n\u001b[1;32m    105\u001b[0m                 actual_version, force_compile, _need_reload))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# It is useless to try to compile if there isn't any\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# compiler!  But we still want to try to load it, in case\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# the cache was copied from another computer.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Version check of the existing lazylinker compiled file. Looking for version 0.211, but found None. Extra debug information: force_compile=False, _need_reload=True",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/vm.py:674\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m theano\u001b[38;5;241m.\u001b[39mgof\u001b[38;5;241m.\u001b[39mcmodule\u001b[38;5;241m.\u001b[39mMissingGXX(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlazylinker will not be imported if theano.config.cxx is not set.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazylinker_c\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCVM\u001b[39;00m(lazylinker_c\u001b[38;5;241m.\u001b[39mCLazyLinker, VM):\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/lazylinker_c.py:139\u001b[0m\n\u001b[1;32m    138\u001b[0m args \u001b[38;5;241m=\u001b[39m cmodule\u001b[38;5;241m.\u001b[39mGCC_compiler\u001b[38;5;241m.\u001b[39mcompile_args()\n\u001b[0;32m--> 139\u001b[0m \u001b[43mcmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGCC_compiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpreargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Save version into the __init__.py file.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/cmodule.py:2410\u001b[0m, in \u001b[0;36mGCC_compiler.compile_str\u001b[0;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[1;32m   2407\u001b[0m     \u001b[38;5;66;03m# We replace '\\n' by '. ' in the error message because when Python\u001b[39;00m\n\u001b[1;32m   2408\u001b[0m     \u001b[38;5;66;03m# prints the exception, having '\\n' in the text makes it more\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;66;03m# difficult to read.\u001b[39;00m\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompilation failed (return status=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   2411\u001b[0m                     (status, compile_stderr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcmodule\u001b[38;5;241m.\u001b[39mcompilation_warning \u001b[38;5;129;01mand\u001b[39;00m compile_stderr:\n\u001b[1;32m   2413\u001b[0m     \u001b[38;5;66;03m# Print errors just below the command line.\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Compilation failed (return status=1): /usr/bin/ld: /usr/local/python/3.10.4/lib/libpython3.10.a(bytearrayobject.o): relocation R_X86_64_PC32 against symbol `_Py_NoneStruct' can not be used when making a shared object; recompile with -fPIC. /usr/bin/ld: final link failed: bad value. collect2: error: ld returned 1 exit status. ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# declare two symbolic floating-point scalars\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/__init__.py:110\u001b[0m\n\u001b[1;32m     97\u001b[0m __api_version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    100\u001b[0m     CLinker, OpWiseCLinker, DualLinker, Linker, LocalLinker, PerformLinker,\n\u001b[1;32m    101\u001b[0m     Container,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     Type, Generic, generic,\n\u001b[1;32m    108\u001b[0m     object2, utils)\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    111\u001b[0m     SymbolicInput, In,\n\u001b[1;32m    112\u001b[0m     SymbolicOutput, Out,\n\u001b[1;32m    113\u001b[0m     Mode,\n\u001b[1;32m    114\u001b[0m     predefined_modes, predefined_linkers, predefined_optimizers,\n\u001b[1;32m    115\u001b[0m     FunctionMaker, function, function_dump,\n\u001b[1;32m    116\u001b[0m     OpFromGraph,\n\u001b[1;32m    117\u001b[0m     ProfileStats,\n\u001b[1;32m    118\u001b[0m     Param, shared, as_op)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msafe_asarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprinting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint, pp\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/compile/__init__.py:12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m         DeepCopyOp, deep_copy_op, register_deep_copy_op_c_code,\n\u001b[1;32m      4\u001b[0m         Shape, shape, register_shape_c_code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         as_op, Rebroadcast, register_rebroadcast_c_code,\n\u001b[1;32m      8\u001b[0m         SpecifyShape, specify_shape, register_specify_shape_c_code)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebugmode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DebugMode\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/compile/mode.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gof\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgof\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvm\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtheano\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m string_types\n",
      "File \u001b[0;32m/usr/local/python/3.10.4/lib/python3.10/site-packages/theano/gof/vm.py:683\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[43mtheano\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgof\u001b[49m\u001b[38;5;241m.\u001b[39mcmodule\u001b[38;5;241m.\u001b[39mMissingGXX) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# OSError happens when g++ is not installed.  In that case, we\u001b[39;00m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# already changed the default linker to something else then CVM.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# Currently this is the py linker.\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# Here we assert that the default linker is not cvm.\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _config_var_list\n\u001b[1;32m    689\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mfullname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinker\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvm\u001b[39m\u001b[38;5;124m'\u001b[39m), e\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'theano' has no attribute 'gof' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tensor.dscalar()\n",
    "b = tensor.dscalar()\n",
    "# create a simple expression\n",
    "c = a + b\n",
    "# convert the expression into a callable object that takes (a,b)\n",
    "# values as input and computes a value for c\n",
    "f = theano.function([a,b], c)\n",
    "# bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c'\n",
    "result = f(1.5, 2.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ed836-e563-4931-9a2d-cc1bcf1c1151",
   "metadata": {},
   "source": [
    "Lesson 02: Introduction to TensorFlow.\n",
    "\n",
    "TensorFlow is a Python library for fast numerical computing created and released by Google. Like Theano, TensorFlow is intended to be used to develop deep learning models.\n",
    "\n",
    "With the backing of Google, perhaps used in some of it’s production systems and used by the Google DeepMind research group, it is a platform that we cannot ignore.\n",
    "\n",
    "Unlike Theano, TensorFlow does have more of a production focus with a capability to run on CPUs, GPUs and even very large clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f208c64-3874-46a7-84f0-c8b40766904b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TensorFlow\n",
      "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setuptools\n",
      "  Using cached setuptools-67.6.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from TensorFlow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from TensorFlow) (1.24.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, setuptools, rsa, pyasn1-modules, protobuf, packaging, opt-einsum, oauthlib, MarkupSafe, markdown, keras, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, requests, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, TensorFlow\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1 requires pillow!=8.3.*,>=5.3.0, which is not installed.\n",
      "matplotlib 3.7.0 requires contourpy>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.0 requires cycler>=0.10, which is not installed.\n",
      "matplotlib 3.7.0 requires fonttools>=4.22.0, which is not installed.\n",
      "matplotlib 3.7.0 requires kiwisolver>=1.0.1, which is not installed.\n",
      "matplotlib 3.7.0 requires pillow>=6.2.0, which is not installed.\n",
      "matplotlib 3.7.0 requires pyparsing>=2.3.1, which is not installed.\n",
      "matplotlib 3.7.0 requires python-dateutil>=2.7, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 TensorFlow-2.11.0 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 h5py-3.8.0 idna-3.4 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 setuptools-67.6.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0 typing-extensions-4.5.0 urllib3-1.26.15 werkzeug-2.2.3 wheel-0.40.0 wrapt-1.15.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f0611c-ca7c-41f7-aab9-957b5adfe9f4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 04:05:13.862672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 04:05:13.989649: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 04:05:13.989676: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 04:05:14.812023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 04:05:14.812159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 04:05:14.812171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/python/3.10.4/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 04:05:18.593049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-20 04:05:18.593086: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-20 04:05:18.593113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-09997c): /proc/driver/nvidia/version does not exist\n",
      "2023-03-20 04:05:18.593378: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 04:05:18.595882: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "# Example of TensorFlow library\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "# create a simple symbolic expression using the add function\n",
    "add = tf.add(a, b)\n",
    "# bind 1.5 to 'a', 2.5 to 'b', and evaluate 'c'\n",
    "sess = tf.Session()\n",
    "binding = {a: 1.5, b: 2.5}\n",
    "c = sess.run(add, feed_dict=binding)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985e0aa-e415-476b-a9e2-da2ac9ea61d1",
   "metadata": {},
   "source": [
    "Lesson 03: Introduction to Keras.\n",
    "\n",
    "A difficulty of both Theano and TensorFlow is that it can take a lot of code to create even very simple neural network models.\n",
    "\n",
    "These libraries were designed primarily as a platform for research and development more than for the practical concerns of applied deep learning.\n",
    "\n",
    "The Keras library addresses these concerns by providing a wrapper for both Theano and TensorFlow. It provides a clean and simple API that allows you to define and evaluate deep learning models in just a few lines of code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab5df0-eab5-4487-9d1e-c0b622757e56",
   "metadata": {},
   "source": [
    "Lesson 04: Crash Course in Multi-Layer Perceptrons.\n",
    "\n",
    "Artificial neural networks are a fascinating area of study, although they can be intimidating\n",
    "when just getting started.\n",
    "\n",
    "Хиймэл мэдрэлийн сүлжээг ихэвчлэн мэдрэлийн сүлжээ эсвэл олон давхаргат гэж нэрлэдэг Перцептронууд нь мэдрэлийн сүлжээний хамгийн ашигтай төрөл юм. \n",
    "\n",
    "Мэдрэлийн сүлжээний барилгын материал нь хиймэл мэдрэлийн эсүүд юм. Эдгээр нь энгийн тооцоолол юм жигнэсэн оролтын дохиотой бөгөөд идэвхжүүлэх функцийг ашиглан гаралтын дохио үүсгэдэг нэгжүүд. Нейронууд нь мэдрэлийн эсийн сүлжээнд байрладаг. \n",
    "\n",
    "Мөрний мэдрэлийн эсийг давхарга ба нэг гэж нэрлэдэг сүлжээ нь олон давхаргатай байж болно. Сүлжээний нейронуудын бүтцийг ихэвчлэн сүлжээний топологи гэж нэрлэдэг. Тохируулсны дараа мэдрэлийн сүлжээг таны өгөгдлийн багц дээр сургах шаардлагатай. Мэдрэлийн сүлжээнд зориулсан сонгодог бөгөөд илүүд үздэг сургалтын алгоритмыг стохастик гэж нэрлэдэг градиент уналт.\n",
    "\n",
    "![model of simple neuron](https://machinelearningmastery.com/wp-content/uploads/2016/05/Neuron.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f748b13-241c-4607-8ddc-b2de2c97f77d",
   "metadata": {},
   "source": [
    "Lesson 05: Develop Your First Neural Network in Keras.\n",
    "\n",
    "1. Load your dataset using NumPy or Pandas.\n",
    "2. Define your neural network model and compile it.\n",
    "3. Fit your model to the dataset.\n",
    "4. Estimate the performance of your model on unseen data.\n",
    "\n",
    "[Datasetfile](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1aad94-b683-4d9a-8485-626b4f9e7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Load the dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# Define and Compile\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy' , optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc2dba9-f7a7-4855-843e-1ebfc13a0695",
   "metadata": {},
   "source": [
    "Lesson 06: Use Keras Models With Scikit-Learn.\n",
    "\n",
    "The scikit-learn library is a general purpose machine learning framework in Python built on top of SciPy.\n",
    "\n",
    "Scikit-learn excels at tasks such as evaluating model performance and optimizing model hyperparameters in just a few lines of code.\n",
    "\n",
    "Keras provides a wrapper class that allows you to use your deep learning models with scikit-learn. For example, an instance of KerasClassifier class in Keras can wrap your deep learning model and be used as an Estimator in scikit-learn.\n",
    "\n",
    "When using the KerasClassifier class, you must specify the name of a function that the class can use to define and compile your model. You can also pass additional parameters to the constructor of the KerasClassifier class that will be passed to the model.fit() call later, like the number of epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27fede6-fdf1-43a1-8c06-cff274174845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# create classifier for use in scikit-learn\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKerasClassifier\u001b[49m(build_fn\u001b[38;5;241m=\u001b[39mcreate_model, nb_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# evaluate model using 10-fold cross validation in scikit-learn\u001b[39;00m\n\u001b[1;32m     13\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "\t# Create model\n",
    "\tmodel = Sequential()\n",
    "\t...\n",
    "\t# Compile model\n",
    "\tmodel.compile(...)\n",
    "\treturn model\n",
    "\n",
    "# create classifier for use in scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10)\n",
    "# evaluate model using 10-fold cross validation in scikit-learn\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd803b-f8a6-4c41-8dfa-816bc89e6949",
   "metadata": {},
   "source": [
    "Lesson 07: Plot Model Training History.\n",
    "\n",
    "You can learn a lot about neural networks and deep learning models by observing their performance over time during training.\n",
    "\n",
    "Keras provides the capability to register callbacks when training a deep learning model.\n",
    "\n",
    "One of the default callbacks that is registered when training all deep learning models is the History callback. It records training metrics for each epoch. This includes the loss and the accuracy (for classification problems) as well as the loss and accuracy for the validation dataset, if one is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe1788a-2fe4-4734-b8ad-e6c077ad8559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# list all data in history\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "history = model.fit(...)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d8112-519b-4960-8ff0-26c4acf3a9de",
   "metadata": {},
   "source": [
    "Lesson 08: Save Your Best Model During Training With Checkpointing.\n",
    "\n",
    "The Keras library provides a checkpointing capability by a callback API. The ModelCheckpoint\n",
    "callback class allows you to define where to checkpoint the model weights, how the file should\n",
    "be named and under what circumstances to make a checkpoint of the model.\n",
    "\n",
    "Checkpointing can be useful to keep track of the model weights in case your training run is stopped prematurely. It is also useful to keep track of the best model observed during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f29ae-4ab3-4d44-b7f3-5e2f1e9d6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "...\n",
    "checkpoint = ModelCheckpoint('weights.best.hdf5', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "model.fit(..., callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da299fb0-d167-4fde-a163-db8e58a547dc",
   "metadata": {},
   "source": [
    "Lesson 09: Reduce Overfitting With Dropout Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da411eb1-ef92-485f-8dd8-4558a159b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "...\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cd202-fc56-40ac-89d7-dc597d314c67",
   "metadata": {},
   "source": [
    "Lesson 10: Lift Performance With Learning Rate Schedules.\n",
    "\n",
    "Often called an adaptive learning rate or an annealed learning rate, this is a technique where the learning rate used by stochastic gradient descent changes while training your model.\n",
    "\n",
    "Keras has a time-based learning rate schedule built into the implementation of the stochastic gradient descent algorithm in the SGD class.\n",
    "\n",
    "When constructing the class, you can specify the decay which is the amount that your learning rate (also specified) will decrease each epoch. When using learning rate decay you should bump up your initial learning rate and consider adding a large momentum value such as 0.8 or 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41da0c-f490-4766-ab90-25429fef81d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "...\n",
    "sgd = SGD(lr=0.1, momentum=0.9, decay=0.0001, nesterov=False)\n",
    "model.compile(..., optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eacc2-170a-47f3-9bbd-9dcf2b292035",
   "metadata": {},
   "source": [
    "Lesson 11: Crash Course in Convolutional Neural Networks.\n",
    "\n",
    "Convolutional Neural Networks are a powerful artificial neural network technique.\n",
    "\n",
    "Тэд жижиг дөрвөлжин оролтын өгөгдлүүдийг ашиглан дотоод шинж чанаруудын дүрслэлийг сурч, зураг дээрх пикселүүдийн хоорондын орон зайн хамаарлыг хүлээж, хадгалж байдаг. \n",
    "\n",
    "Онцлогыг бүхэл бүтэн зурганд сургаж, ашигладаг бөгөөд энэ нь таны зураг дээрх объектуудыг тухайн газарт шилжүүлэх эсвэл хөрвүүлэх боломжийг олгодог бөгөөд сүлжээгээр илрүүлэх боломжтой хэвээр байна. Ийм учраас энэ төрлийн сүлжээ нь гэрэл зураг дээрх объектыг таних, өөр өөр чиглэлтэй цифрүүд, нүүр царай, объектуудыг сонгоход маш их хэрэгтэй байдаг.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10dc8f-1484-4852-a6b0-bc94b065e6d5",
   "metadata": {},
   "source": [
    "Lesson 12: Handwritten Digit Recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada2bd1-12e5-45dc-90eb-5f50f2c7e456",
   "metadata": {},
   "source": [
    "Lesson 13: Object Recognition in Small Photographs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc034f98-395c-4edf-ab97-9b9a8bbdd24e",
   "metadata": {},
   "source": [
    "Lesson 14: Improve Generalization With Data Augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07fc14d-a946-4df5-a973-1fb7fd954dc2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
